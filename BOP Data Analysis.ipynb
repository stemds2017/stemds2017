{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2016 = pd.read_csv('C:\\\\Users\\\\Francis\\\\Google Drive\\\\Data\\\\___PACE\\\\STEM-Summer2017\\\\expeditions2016.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2017 = pd.read_csv('C:\\\\Users\\\\Francis\\\\Google Drive\\\\Data\\\\___PACE\\\\STEM-Summer2017\\\\expeditions2017.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at the first five rows\n",
    "data2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the column names\n",
    "data2016.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at the last five rows\n",
    "data2016.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at the first five rows\n",
    "data2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at the last five rows\n",
    "data2016.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transpose the data -- interchange rows and columns\n",
    "data2016 = data2016.T\n",
    "data2017 = data2017.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change the column names to the row labels\n",
    "data2016.columns = data2016.iloc[0]\n",
    "data2017.columns = data2017.iloc[0]\n",
    "\n",
    "# since the first row of the transposed data contains the variable names and not data\n",
    "# repalce the data frame with all but the first row\n",
    "data2016 = data2016.iloc[1:]\n",
    "data2017 = data2017.iloc[1:]\n",
    "\n",
    "# take a look and make sure you got what you wanted\n",
    "data2016.head()\n",
    "data2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2016.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# you can print all the variable names\n",
    "for i in range(len(data2016.columns)):\n",
    "    print(data2016.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print all the variable names\n",
    "for i in range(len(data2017.columns)):\n",
    "    print(data2017.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# you can explore specific subsets of the data\n",
    "for i in range(0, 3):\n",
    "    print(data2016.iloc[i][\"Measurements (mm)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the measuremts for all substrates for the second expedition\n",
    "data2016.iloc[1][\"Measurements (mm)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# You can select multiple columns by using an array as the index\n",
    "data2016[[\"Measurements (mm)\", \"Total number of all live oysters\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# same\n",
    "data2017[[\"Measurements (mm)\", \"Total number of all live oysters\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine multiple dataframes\n",
    "# axis = n tells concat if you want to combine rowise or columnwise\n",
    "dataall = pd.concat([data2016, data2017], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataall.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataall.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataall[\"Measurements (mm)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the values for each substrate shell for one expedition\n",
    "# Recall the expeditions are the rows so we use .iloc to pass the index location (row number)\n",
    "# This will create an array of strings, each string contains the measurements\n",
    "# vals is of type numpy.ndarray, and each element of vals is a str\n",
    "vals = data2016.iloc[0][\"Measurements (mm)\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the dtype for vals\n",
    "type(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the dtype for the first element of vals\n",
    "type(vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vals[0].split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can't find the mean yet because this is a list of str \n",
    "vals[0].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map let's us map the list of str to floats\n",
    "# but we can't use this yet, so we make it a list of floats\n",
    "# then make it a numpy.ndarray or a pandas.Series\n",
    "n = np.array(list(map(float, vals[0].split(\",\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = pd.Series(list(map(float, vals[0].split(\",\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the data\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also convert from str to float using np.asfloat()\n",
    "np.array(vals[0].split(\",\")).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(vals[0].split(\",\")).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can summarize and display the means for each substrate within one expedition.\n",
    "for v in range(len(vals)):\n",
    "    print('Substrate Shell #' + str(v+1) + \"\\tmean =\", '%.3f' % np.array(list(map(float, vals[v].split(\",\")))).mean(), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This stacks all the measurements into one vector based on Water Color\n",
    "wc = 'Water color\\r\\n(1=Light Blue,2=Dark Blue,3=Light Green,\\r\\n4=Dark Green,5=Light Brown,6=Dark Brown)'\n",
    "\n",
    "v1 = np.array([])\n",
    "v3 = np.array([])\n",
    "v4 = np.array([])\n",
    "v5 = np.array([])\n",
    "v6 = np.array([])\n",
    "for l in range(len(data2016[\"Measurements (mm)\"].values)):\n",
    "    # temp stores the observations for one expedition\n",
    "    for t in range(10):\n",
    "        if pd.notnull(data2016.iloc[l]['Measurements (mm)'].values[t]):\n",
    "            w = np.array(data2016.iloc[l][\"Measurements (mm)\"].values[t].split(\",\")).astype(float)\n",
    "            if data2016.iloc[l][wc] == '1':\n",
    "                v1 = np.append(v1, w)\n",
    "            elif data2016.iloc[l][wc] == '3':\n",
    "                v3 = np.append(v3, w)\n",
    "            elif data2016.iloc[l][wc] == '4':\n",
    "                v4 = np.append(v4, w)\n",
    "            elif data2016.iloc[l][wc] == '5':\n",
    "                v5 = np.append(v5, w)\n",
    "            else:\n",
    "                v6 = np.append(v6, w)\n",
    "        else:\n",
    "            next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine the measurements with water color into a new data frame\n",
    "measures = np.concatenate((v1, v3, v4, v5, v6), axis=0)\n",
    "measures = pd.DataFrame({'Measures': measures})\n",
    "\n",
    "measures['WaterColor'] = np.zeros(len(measures['Measures']))\n",
    "\n",
    "measures.loc[0:len(v1), 'WaterColor'] = 1\n",
    "measures.loc[len(v1):len(v1)+len(v3), 'WaterColor'] = 3\n",
    "measures.loc[len(v1)+len(v3):len(v1)+len(v3)+len(v4), 'WaterColor'] = 4\n",
    "measures.loc[len(v1)+len(v3)+len(v4):len(v1)+len(v3)+len(v4)+len(v5), 'WaterColor'] = 5\n",
    "measures.loc[len(v1)+len(v3)+len(v4)+len(v5):len(v1)+len(v3)+len(v4)+len(v4)+len(v5)+len(v6), 'WaterColor'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "measures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.groupby('WaterColor').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.groupby('WaterColor').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures['Measures'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.groupby('WaterColor').mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.groupby('WaterColor').size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the measurements data into two equal parts \n",
    "# then plot them\n",
    "# in reality you would notmally plot two different variables to observe any relationship\n",
    "a = np.array(measures.loc[0:488]['Measures'])\n",
    "b = np.array(measures.loc[489:978]['Measures'])\n",
    "bob = pd.DataFrame({'a': a, 'b': b})\n",
    "bob.plot.scatter(x = 'a', y = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN this example, I made up a second variable to plot against my measurements data\n",
    "# I added random normal fluctuations to the measurements data\n",
    "measures['Noise'] = measures['Measures'] + np.random.normal(0,4,978)\n",
    "measures.plot.scatter(y = 'Noise', x = 'Measures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "measures['Measures'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = np.array([[np.random.normal(0,1,100)],[np.random.normal(0.5,0.8,100)]])\n",
    "plt.scatter(rn[0], rn[1])\n",
    "plt.title('Zero Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.random.normal(0,1,100)\n",
    "rn = np.array([w,w+2*np.random.normal(0,0.1,100)])\n",
    "plt.scatter(rn[0], rn[1])\n",
    "plt.title('Positive Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = np.random.normal(0,1,100)\n",
    "rn = np.array([w, -w+3*np.random.normal(0.5,0.1,100)])\n",
    "plt.scatter(rn[0], rn[1])\n",
    "plt.title('Negative Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures['Measures'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(measures['Measures'], measures['Noise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(bob['a'], bob['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho, pstat = sp.stats.pearsonr(measures['Measures'], measures['Noise'])\n",
    "print('rho = %.4f' % rho, 'p-val = %.4f' % pstat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstat, pval = sp.stats.ttest_ind(measures['Measures'], measures['Noise'])\n",
    "print('t-stat = %.3f ' % tstat, 'p-value = %.3f' % pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstat, pval = sp.stats.ttest_ind(v1, v5)\n",
    "print('t-stat = %.3f ' % tstat, 'p-value = %.3f' % pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to test if there is a difference in the means from multiple groups\n",
    "# use Analysis of Variance(ANOVA) \n",
    "fstat, pval = stats.f_oneway(v1, v3, v4, v5, v6)\n",
    "print('ANOVA Results', 'fstat = %.3f' % fstat, 'p-value = %.3f' % pval, '\\n', sep='\\t')\n",
    "\n",
    "# The null nypothesis for ANOVA is all means are equal\n",
    "# If your test suggests rejecting the null you need to do a Tukey HSD comparison\n",
    "# to see which pairs of means are different\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "print(pairwise_tukeyhsd(measures['Measures'], measures['WaterColor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing the pH data issue for out of bounds data\n",
    "phs = pd.Series(['17.6', '8.2', '7.5'])\n",
    "phsf = phs.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phsf[phsf > 14.0] = np.nan\n",
    "phsf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
